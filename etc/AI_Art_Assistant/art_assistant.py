import gradio as gr
import requests
import base64
from PIL import Image
import io
import numpy as np
import cv2
import os
from dotenv import load_dotenv
from openai import OpenAI

# ---------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
# ---------------------------------------------------------
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ (API Keyê°€ .env íŒŒì¼ì— ìˆì–´ì•¼ í•¨)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Stable Diffusion WebUI ì„œë²„ ì£¼ì†Œ (ì„œë²„ ì¼¤ ë•Œë§ˆë‹¤ í™•ì¸ í•„ìš”)
WEBUI_URL = ""
CONTROLNET_MODEL_NAME = "kohya_controllllite_xl_canny [2ed264be]"

# ---------------------------------------------------------
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------
def pil_to_base64(pil_image):
    with io.BytesIO() as stream:
        pil_image.save(stream, "PNG", pnginfo=None)
        return base64.b64encode(stream.getvalue()).decode('utf-8')

def process_pony_prompt(user_prompt, negative_prompt):
    # Pony ëª¨ë¸ìš© í€„ë¦¬í‹° íƒœê·¸ ìë™ ì£¼ì…
    quality_tags = "score_9, score_8_up, score_7_up, score_6_up, source_anime, high quality, "
    full_prompt = quality_tags + user_prompt
    
    base_negative = "score_4, score_5, score_6, low quality, bad anatomy, worst quality, text, watermark, "
    full_negative = base_negative + negative_prompt
    return full_prompt, full_negative

# ---------------------------------------------------------
# 3. ì±—ë´‡ ë¡œì§ (ìˆ˜ë™ Chatbot ëŒ€ì‘)
# ---------------------------------------------------------
def chat_response(message, history):
    """
    ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ GPT ë‹µë³€ì„ ìƒì„±í•˜ê³ ,
    Gradio 4.x í‘œì¤€ í¬ë§·ì¸ [ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸]ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # â˜… ìˆ˜ì •ë¨: ì‚¬ìš©ìê°€ 'ì œì™¸'ë¥¼ ìš”ì²­í•˜ë©´ Negative Promptì— ì¶”ê°€í•˜ë„ë¡ ì§€ëŠ¥í˜• ì§€ì‹œ â˜…
    system_prompt = (
        "ë„ˆëŠ” Stable Diffusion(Pony XL) ì „ë¬¸ê°€ì¸ AI ì•„íŠ¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. "
        "ì‚¬ìš©ìê°€ ì¼ìƒì ì¸ ëŒ€í™”ë¥¼ í•˜ë©´ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µí•´ì¤˜. "
        "í•˜ì§€ë§Œ ì‚¬ìš©ìê°€ 'ê·¸ë¦¼ ê·¸ë ¤ì¤˜', 'í”„ë¡¬í”„íŠ¸ ì§œì¤˜' ê°™ì€ ìš”ì²­ì„ í•˜ë©´, "
        "ë°˜ë“œì‹œ 'Danbooru ìŠ¤íƒ€ì¼ì˜ íƒœê·¸(Tag)' í˜•ì‹ìœ¼ë¡œ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•´. "
        "ë¬¸ì¥ì´ ì•„ë‹ˆë¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ë“¤ì„ ë‚˜ì—´í•´ì¤˜. "
        "\n"
        "â˜…ì¤‘ìš”â˜…: ì‚¬ìš©ìê°€ 'íˆ¬êµ¬ëŠ” ë¹¼ì¤˜', 'ì•ˆê²½ ì—†ì´' ê°™ì´ íŠ¹ì • ìš”ì†Œë¥¼ ì œì™¸í•´ë‹¬ë¼ê³  í•˜ë©´, "
        "ê·¸ ë‹¨ì–´(ì˜ˆ: helmet, glasses)ë¥¼ ë°˜ë“œì‹œ 'Negative Prompt' ë§¨ ì•ì— ì¶”ê°€í•´ì¤˜."
        "\n"
        "ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì§€ì¼œì¤˜:\n"
        "ì„¤ëª…: (í•œêµ­ì–´ë¡œ ê·¸ë¦¼ì— ëŒ€í•œ ì„¤ëª…)\n"
        "Positive Prompt: (ë³µì‚¬í•´ì„œ ì“¸ ìˆ˜ ìˆëŠ” ì˜ë¬¸ íƒœê·¸ ë‚˜ì—´. ì˜ˆ: 1girl, solo, red armor...)\n"
        "Negative Prompt: (ì œì™¸í•  ë‹¨ì–´ë“¤ + ê¸°ë³¸ ë¶€ì • íƒœê·¸ë“¤. ì˜ˆ: helmet, beard, low quality, bad anatomy, extra fingers, mutation...)"
    )
    
    # historyëŠ” ì´ì œ [{'role': 'user', 'content': '...'}, {'role': 'assistant', 'content': '...'}] í˜•íƒœì…ë‹ˆë‹¤.
    
    # 1. GPTì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„± (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì´ì „ ëŒ€í™”)
    messages = [{"role": "system", "content": system_prompt}]
    
    for msg in history:
        messages.append({"role": msg['role'], "content": msg['content']})
    
    # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    messages.append({"role": "user", "content": message})

    # 2. OpenAI API í˜¸ì¶œ
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=600
        )
        bot_reply = response.choices[0].message.content
    except Exception as e:
        bot_reply = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # 3. Gradio í™”ë©´ ì—…ë°ì´íŠ¸ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì¶”ê°€)
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": bot_reply})
    
    return "", history # ì…ë ¥ì°½ ë¹„ìš°ê¸°, íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸

# ---------------------------------------------------------
# 4. ì´ë¯¸ì§€ ìƒì„± ë¡œì§
# ---------------------------------------------------------
def generate_canny(sketch_dict, prompt_text, negative_prompt):
    if sketch_dict is None:
        return None, None # ì˜ˆì™¸ ì²˜ë¦¬

    # ë°°ê²½(ì„ í™”ìš©)ê³¼ ì±„ìƒ‰ ë ˆì´ì–´ ë¶„ë¦¬
    clean_line_art = sketch_dict["background"]
    colored_draft = sketch_dict["composite"]
    
    if not clean_line_art:
        clean_line_art = colored_draft

    # ë¦¬ì‚¬ì´ì§•
    width, height = 1024, 1024
    clean_resized = clean_line_art.resize((width, height))
    colored_resized = colored_draft.resize((width, height))
    
    # Canny ì¶”ì¶œ
    image_np = np.array(clean_resized)
    if image_np.shape[-1] == 4: image_np = image_np[:, :, :3]
    canny_np = cv2.Canny(image_np, 50, 100) 
    canny_image_pil = Image.fromarray(canny_np)

    init_base64 = pil_to_base64(colored_resized)
    canny_base64 = pil_to_base64(canny_image_pil)
    final_prompt, final_negative = process_pony_prompt(prompt_text, negative_prompt)

    payload = {
        "prompt": final_prompt,
        "negative_prompt": final_negative,
        "init_images": [init_base64], 
        "steps": 28,
        "width": width,
        "height": height,
        "cfg_scale": 7.0,
        "sampler_name": "Euler a",
        "denoising_strength": 0.85, 
        "alwayson_scripts": {
            "controlnet": {
                "args": [{
                    "image": canny_base64,
                    "module": "none", 
                    "model": CONTROLNET_MODEL_NAME,
                    "weight": 1.2,
                    "control_mode": "ControlNet is more important",
                }]
            }
        }
    }

    try:
        response = requests.post(url=f'{WEBUI_URL}/sdapi/v1/img2img', json=payload, timeout=600)
        response.raise_for_status()
        r = response.json()
        if 'images' in r:
            return Image.open(io.BytesIO(base64.b64decode(r['images'][0]))), canny_image_pil
    except Exception as e:
        print(f"Error: {e}")
        return None, None

def generate_inpaint(image_editor_dict, prompt_text, negative_prompt):
    if not image_editor_dict or not image_editor_dict["layers"]:
        return None

    init_img = image_editor_dict["background"]
    mask_layer = image_editor_dict["layers"][0]

    mask_np = np.array(mask_layer)
    if mask_np.shape[2] == 4:
        mask_image = Image.fromarray(mask_np[:, :, 3]).convert("L")
    else:
        mask_image = mask_layer.convert("L")

    width, height = 1024, 1024
    init_img_resized = init_img.resize((width, height))
    mask_img_resized = mask_image.resize((width, height))

    init_base64 = pil_to_base64(init_img_resized)
    mask_base64 = pil_to_base64(mask_img_resized)
    final_prompt, final_negative = process_pony_prompt(prompt_text, negative_prompt)

    payload = {
        "prompt": final_prompt,
        "negative_prompt": final_negative,
        "init_images": [init_base64],
        "mask": mask_base64,
        "steps": 35,
        "width": width,
        "height": height,
        "cfg_scale": 7.0,
        "sampler_name": "Euler a",
        "mask_blur": 4,
        "inpainting_fill": 1,
        "inpaint_full_res": True,
        "denoising_strength": 0.75
    }

    try:
        response = requests.post(url=f'{WEBUI_URL}/sdapi/v1/img2img', json=payload, timeout=600)
        response.raise_for_status()
        r = response.json()
        if 'images' in r:
            return Image.open(io.BytesIO(base64.b64decode(r['images'][0])))
    except Exception as e:
        print(f"Error: {e}")
        return None

# ---------------------------------------------------------
# 5. í†µí•© UI êµ¬ì„±
# ---------------------------------------------------------
with gr.Blocks() as demo:
    gr.HTML("""<style>footer {visibility: hidden; display: none !important;}</style>""")

    gr.Markdown("# ğŸ¨ AI Creative Studio")
    gr.Markdown("ì±—ë´‡ê³¼ ìƒì˜í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ê³ , ì•„íŠ¸ ìŠ¤íŠœë””ì˜¤ì—ì„œ ë‚˜ë§Œì˜ ì‘í’ˆì„ ì™„ì„±í•˜ì„¸ìš”.")

    with gr.Tabs():
        # [Tab 1] ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
        with gr.TabItem("ğŸ¤– AI í”„ë¡¬í”„íŠ¸ ì±—ë´‡"):
            gr.Markdown("### ğŸ’¡ ë¬´ì—‡ì„ ê·¸ë¦¬ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
            
            chatbot = gr.Chatbot(label="ëŒ€í™”ì°½", height=400)
            msg = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì˜ˆ: íˆ¬êµ¬ ì—†ëŠ” ê¸°ì‚¬ ê·¸ë ¤ì¤˜")
            clear = gr.Button("ëŒ€í™” ì§€ìš°ê¸°")

            # ì´ë²¤íŠ¸ ì—°ê²°
            msg.submit(chat_response, [msg, chatbot], [msg, chatbot])
            clear.click(lambda: [], None, chatbot, queue=False)

        # [Tab 2] ì•„íŠ¸ ìŠ¤íŠœë””ì˜¤
        with gr.TabItem("ğŸ¨ ì•„íŠ¸ ìŠ¤íŠœë””ì˜¤"):
            gr.Markdown("### ğŸ› ï¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”")
            
            with gr.Tabs():
                # [Sub-Tab A] ìŠ¤ì¼€ì¹˜ -> ì´ë¯¸ì§€
                with gr.TabItem("ìŠ¤ì¼€ì¹˜ ì™„ì„±"):
                    with gr.Row():
                        with gr.Column():
                            sketch_input = gr.ImageEditor(
                                label="ìŠ¤ì¼€ì¹˜", 
                                type="pil", 
                                height=500,
                                brush=gr.Brush(colors=["#000000", "#FF0000", "#00FF00", "#0000FF"], default_size=4)
                            )
                            s_prompt = gr.Textbox(label="í”„ë¡¬í”„íŠ¸ (Positive Prompt ë³µì‚¬)", placeholder="1girl, silver armor...")
                            s_neg = gr.Textbox(label="ë¶€ì • í”„ë¡¬í”„íŠ¸ (Negative Prompt ë³µì‚¬)", value="low quality, bad anatomy, worst quality, text, watermark")
                            s_btn = gr.Button("âœ¨ ìŠ¤ì¼€ì¹˜ë¡œ ìƒì„±í•˜ê¸°", variant="primary")
                        
                        with gr.Column():
                            s_result = gr.Image(label="ì™„ì„±ëœ ì´ë¯¸ì§€")
                            s_debug = gr.Image(label="Canny ë¯¸ë¦¬ë³´ê¸°", height=200)

                    s_btn.click(generate_canny, [sketch_input, s_prompt, s_neg], [s_result, s_debug])

                # [Sub-Tab B] ì¸í˜ì¸íŒ…
                with gr.TabItem("ë¶€ë¶„ ìˆ˜ì •"):
                    with gr.Row():
                        with gr.Column():
                            inpaint_input = gr.ImageEditor(
                                label="ìˆ˜ì •í•  ì´ë¯¸ì§€", 
                                type="pil", 
                                height=500,
                                brush=gr.Brush(colors=["#FFFFFF"], default_size=15)
                            )
                            i_prompt = gr.Textbox(label="ìˆ˜ì • ë‚´ìš©", placeholder="red eyes...")
                            i_neg = gr.Textbox(label="ë¶€ì • í”„ë¡¬í”„íŠ¸", value="low quality, bad anatomy")
                            i_btn = gr.Button("ğŸ–Œï¸ ë¶€ë¶„ ìˆ˜ì •í•˜ê¸°", variant="primary")
                        
                        with gr.Column():
                            i_result = gr.Image(label="ìˆ˜ì •ëœ ì´ë¯¸ì§€")

                    i_btn.click(generate_inpaint, [inpaint_input, i_prompt, i_neg], [i_result])

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)